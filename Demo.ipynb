{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import data_utils\n",
    "\n",
    "from model import BaselineNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 words loaded (0 invalid format)\n",
      "31009 words loaded (0 invalid format)\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe embedding (filtered on SNLI dataset words)\n",
    "embedding_path = os.path.join('data','glove','glove.filtered.300d.txt')\n",
    "glove_emb = data_utils.EmbeddingGlove(embedding_path)\n",
    "\n",
    "# Build vocabulary\n",
    "vocab = data_utils.Vocabulary()\n",
    "vocab.count_glove(glove_emb)\n",
    "vocab.build()\n",
    "\n",
    "# Initialise dummy dataloader\n",
    "dataloader = data_utils.DataLoaderSnli([], vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31011 words in the vocabulary\n",
      "Most common: ['<unk>', '<pad>', 'the', 'and', 'to', 'of', 'a', 'in', 'is', 'for']\n",
      "tensor([[  19,    8,    6, 2948,    1,    1,    1,    1],\n",
      "        [   2, 1790,   94,   26,   82,   55,    0, 1515],\n",
      "        [4866,   58,   22,  403,    4, 2021,  103,    1]])\n"
     ]
    }
   ],
   "source": [
    "# Number of words in vocabulary\n",
    "print(len(vocab), \"words in the vocabulary\")\n",
    "# Most common words in SNLI\n",
    "print(\"Most common:\",vocab.i2w[:10])\n",
    "\n",
    "# Embeddings\n",
    "print(dataloader.prepare_sentences(\\\n",
    "    [\"This is a sentence\",\n",
    "    \"The cat did not know what 'miouuuuw' meant.\",\n",
    "    \"Surprisingly, there was nothing to surprise us\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise network with word embeddings\n",
    "device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device_name)\n",
    "net = BaselineNet(glove_emb.embedding).to(device)\n",
    "# Load checkpoint\n",
    "checkpoint_path = os.path.join('output','baseline','experiment_23075505','checkpoints','model_iter_102000.pt')\n",
    "state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contradiction\n",
      "neutral\n",
      "entailment\n"
     ]
    }
   ],
   "source": [
    "premise_sent    = \"It was a sunny day, and Silvan decided to go outside to play with his friends\"\n",
    "\n",
    "# Predict\n",
    "CLASS_TEXT = ['neutral', 'contradiction', 'entailment']\n",
    "for hypothesis_sent in [ \\\n",
    "       \"Silvan has a deadline\",\n",
    "       \"Silvan made the decision to play outside\",\n",
    "       \"Silvan decided to go outside\"]:\n",
    "    prem, hyp, _ = dataloader.prepare_manual(premise_sent, hypothesis_sent)\n",
    "    prediction = net.forward(prem, hyp)[0]\n",
    "    print(CLASS_TEXT[prediction.detach().numpy().argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
